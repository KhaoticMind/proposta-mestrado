% !TeX spellcheck = pt_br

%% abtex2-modelo-projeto-pesquisa.tex, v-1.9.5 laurocesar
%% Copyright 2012-2015 by abnTeX2 group at http://www.abntex.net.br/
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%%
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on
%% http://www.abntex.net.br/
%%
%% This work consists of the files abntex2-modelo-projeto-pesquisa.tex
%% and abntex2-modelo-references.bib
%%

% ------------------------------------------------------------------------
% ------------------------------------------------------------------------
% - abnTeX2: Modelo de Projeto de pesquisa em conformidade com
% - ABNT NBR 15287:2011 Informação e documentação - Projeto de pesquisa -
% - Apresentação
% ------------------------------------------------------------------------
% ------------------------------------------------------------------------

\documentclass[
	% -- opções da classe memoir --
	12pt,				% tamanho da fonte
	openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
	twoside,			% para impressão em verso e anverso. Oposto a oneside
	a4paper,			% tamanho do papel.
	% -- opções da classe abntex2 --
	%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
	%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
	%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
	%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
	% -- opções do pacote babel --
	english,			% idioma adicional para hifenização
%	french,				% idioma adicional para hifenização
	spanish,			% idioma adicional para hifenização
	brazil,				% o último idioma é o principal do documento
	]{abntex2}

% ---
% -PACOTES
% ---

% ---
% Pacotes fundamentais
% ---
\usepackage{lmodern}			% Usa a fonte Latin Modern
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{microtype} 			% para melhorias de justificação
% ---

% ---
% Pacotes adicionais, usados apenas no âmbito do Modelo Canônico do abnteX2
% ---
\usepackage{lipsum}				% para geração de dummy text
% ---

% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT

% ---
% -CONFIGURAÇÕES DE PACOTES
% ---

% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		Nenhuma citação no texto.%
	\or
		Citado na página #2.%
	\else
		Citado #1 vezes nas páginas #2.%
	\fi}%
% ---

% ---
% Informações de dados para CAPA e FOLHA DE ROSTO
% ---
\titulo{Proposta para utilização de Processamento Natural de Linguagem no Contexto de Abstração de Logs como Suporte aos Sistemas de Deteção de Intrusão}
\autor{Antonio Augusto Oliveira Viana Santos}
\local{Brasil}
\data{07-2016}
\instituicao{%
  Universidade Federal de Sergipe -- UFS
  \par
  PROCC - Programa de Pós-graduação em Ciência da Computação}
\tipotrabalho{Proposta de Mestrado}
% O preambulo deve conter o tipo do trabalho, o objetivo,
% o nome da instituição e a área de concentração
\preambulo{Proposta de Mestrado para PROCC sob orientação do Prof. Dr. Rogério P. C. do Nascimento}
% ---

% ---
% Configurações de aparência do PDF final

% alterando o aspecto da cor azul
\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
\makeatletter
\hypersetup{
     	%pagebackref=true,
		pdftitle={\@title},
		pdfauthor={\@author},
    	pdfsubject={\imprimirpreambulo},
	    pdfcreator={LaTeX with abnTeX2},
		pdfkeywords={aprendizado de máquina} {abstração de logs }{processamento de texto} {PNL},
		colorlinks=true,       		% false: boxed links; true: colored links
    	linkcolor=blue,          	% color of internal links
    	citecolor=blue,        		% color of links to bibliography
    	filecolor=magenta,      		% color of file links
		urlcolor=blue,
		bookmarksdepth=4
}
\makeatother
% ---

% ---
% Espaçamentos entre linhas e parágrafos
% ---

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

% ---
% compila o indice
% ---
\makeindex
% ---

% ----
% Início do documento
% ----
\begin{document}

% Seleciona o idioma do documento (conforme pacotes do babel)
%\selectlanguage{english}
\selectlanguage{brazil}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing

% ----------------------------------------------------------
% -ELEMENTOS PRÉ-TEXTUAIS
% ----------------------------------------------------------
% \pretextual

% ---
% Capa
% ---
\imprimircapa
% ---

% ---
% Folha de rosto
% ---
\imprimirfolhaderosto
% ---

% ---
% -NOTA DA ABNT NBR 15287:2011, p. 4:
%  ``Se exigido pela entidade, apresentar os dados curriculares do autor em
%     folha ou página distinta após a folha de rosto.''
% ---

% ---
% inserir lista de ilustrações
% ---
%\pdfbookmark[0]{\listfigurename}{lof}
%\listoffigures*
%\cleardoublepage
% ---

% ---
% inserir lista de tabelas
% ---
%\pdfbookmark[0]{\listtablename}{lot}
%\listoftables*
%\cleardoublepage
% ---

% ---
% inserir lista de abreviaturas e siglas
% ---
%\begin{siglas}
%  \item[ABNT] Associação Brasileira de Normas Técnicas
%  \item[abnTeX] ABsurdas Normas para TeX
%\end{siglas}
% ---

% ---
% inserir lista de símbolos
% ---
%\begin{simbolos}
%  \item[$ \Gamma $] Letra grega Gama
%  \item[$ \Lambda $] Lambda
%  \item[$ \zeta $] Letra grega minúscula zeta
%  \item[$ \in $] Pertence
%\end{simbolos}
% ---

% ---
% inserir o sumario
% ---
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\cleardoublepage
% ---


% ----------------------------------------------------------
% -ELEMENTOS TEXTUAIS
% ----------------------------------------------------------
\textual

% ----------------------------------------------------------
% Introdução
% ----------------------------------------------------------
\chapter[Contextualização]{Contextualização}

Durante os últimos anos, a segurança da informação tem sido uma grande preocupação para todos os usuários da Internet, devido aos diversos ataques que vem sendo perpetrados por meio dessa rede global. Segundo dados do CERT.br, o número total de notificações de incidentes de segurança superou a marca de um milhão em 2014, um aumento de mais de 200\% em relação ao ano anterior \cite{incidentes2015incidentes}. Para tentar mitigar esses incidentes a comunidade de segurança da informação vem desenvolvendo ferramentas e padrões para tornar os sistemas de computação mais seguros, de modo a dificultar o acesso a informações valiosas à pessoas não autorizadas. No entanto, os profissionais da área concordam em afirmar que não existe um sistema de segurança perfeito, apesar das técnicas e aplicações desenvolvidas \cite{dua2011data}.

Por esse motivo, as empresas que precisam de mais segurança optam por implantar Sistemas de Detecção de Intrusão (IDS, na sigla em inglês). O objetivo desses sistemas não é evitar que pessoas não autorizadas tenham acesso aos sistemas e/ou dados, mas detetar quando tais tentativas ocorram. Os primeiros trabalhos sobre IDSs são da década de 80 \cite{anderson1980computer, denning1987intrusion} e a partir de então vários trabalhos tem sido realizados para garantir que os IDSs possam sempre atender às demandas dos ambientes onde estão inseridos. Um dos principais desafios enfrentados por esses sistemas é o grande volume de dados que devem ser analisados, processados e exibidos de forma intuitiva para o usuário final \cite{big2013big, nassar2013secure}.

%Além disso, estas tentativas de invasão através da Internet ou de outra rede de computadores, estão se tornando mais elaboradas devido à constante criação de novos ataques ou de variantes de ataques existentes \cite{zuech2015intrusion}. Dessa maneira acreditamos que o futuro da deteção de intrusão depende de melhorias na deteção baseada em anomalias, visto que a deteção baseada em assinaturas oferece pouca capacidade de lidar com a velocidade com que novos ataques são gerados.

Um tipo de dado comumente usados pelos IDSs são os registros gerados durante a operação dos sistemas de computação. Os registros a que nos referimos são costumeiramente chamados de \emph{logs}, e são gerados em pontos específicos da operação do sistema, de acordo com uma programação prévia. Esse registros são importantes pois contém informações que podem ser usadas para diversos fins, entre eles, a deteção de intrusão \cite{jiang2008automated,oliner2012advances,nagappan2010abstracting}. A importância da deteção de invasão por meio da análise de \emph{logs} é clara quando vemos que ela é um requerimento de diversos campos de atuação, onde a segurança da informação se mostra como uma grande preocupação. O padrão \emph{PCI DSS}, aplicado à indústria de cartões de créditos, e a lei \emph{Sarbanese Oaxley}, válida para empresas com ações na bolsa de valores de Nova York, tem esse requisito.

Para que a análise de \emph{logs} possa ser feita de forma efetiva e dar o retorno esperado pelas equipes de segurança da informação, temos de tratar dois pontos importantes: o volume de dados gerados e a falta de estrutura dos logs.

No primeiro caso, a mesma característica que dá aos \emph{logs} sua importância é o que torna difícil seu manuseio: a grande quantidade de informações que eles possuem \cite{brugger2001data,miranskyy2016data,nagappan2010abstracting,vaarandi2003data}. O volume de dados gerados por sistemas de computador, em grandes empresas, pode facilmente chegar a dezenas de gigabytes por dia, existindo casos onde é gerados 1 terabyte de \emph{logs} a cada dia \cite{yen2013beehive}. A analise manual ainda é um dos principais meios para extração de informação dos \emph{logs}. Mas, dado o volume de informação com que estamos trabalhando, fica claro que essa abordagem esta fadada ao fracasso.

Já sobre a falta de estrutura dos \emph{logs}, podemos tomar como exemplo os sistemas operacionais baseados em UNIX\texttrademark. Esse tipo de sistema é amplamente usados em servidores \cite{w3techs-osusage} e possui como padrão para a geração de \emph{logs} o formato \emph{syslog}. Nesse formato os registros de eventos são em texto plano e, em sua maioria, escritas em linguagem natural (como o inglês). O uso de linguagem corrente torna esses \emph{logs} de fácil interpretação por humanos. No entanto, isso os torna difíceis de serem analisados por máquinas.

Uma técnica que se propõe a atacar esses problemas é a de abstração de \emph{logs}. A abstração de \emph{logs} se baseia no fato de que, apesar do grande volume de dados gerados, e sua aparente falta de estrutura, os logs são gerados a partir de poucas instruções bem definidas e parametrizadas. Os parâmetros são chamados de elementos dinâmicos do \emph{log}, enquanto os demais itens, que não se alteram, formam sua parte estática. Dessa forma, dados milhares de registros, esses podem ser mapeados (abstraídos) para alguns poucos tipos básicos.

A abstração de \emph{logs} pode ser feita de forma manual ou automática. A abordagem manual é feita gerando padrões de texto de forma manual através do uso de expressões regulares. Dessa forma os eventos que casam com uma expressão podem ser agrupados como sendo de um único tipo. Assim é possível a extração das ``entidades'' que compõe uma linha de \emph{log}. Por entidades nos referimos aos \emph{hosts}, \emph{ips}, usuários, etc, que são referidos em uma entrada de \emph{log}. No entanto tal atividade possui várias desvantagens: sua elaboração demanda muito tempo; é propensa a erros; necessita de manutenção quando de uma nova versão de software e para serem feitas com sucesso necessitam de profissionais com experiência nos sistemas que geram os registros.

Já as técnicas automáticas são mais restritas. Tais técnicas analisam o texto dos registros de eventos e agrupam linhas similares (sintaticamente falando), de forma a mapea-las a um único meta-evento. Durante esse processo alguns algoritmos descartam as informações das entidades dos \emph{logs} e se preocupam somente com a parte estática, o que acreditamos retirar informações valiosas dos \emph{logs}. No entanto, tanto soluções que mantem as entidades quanto as que retiram, ainda não conseguem abstrair os eventos de forma confiável e por isso seu uso é limitado.

Para combinar a expressividade da abordagem manual, e a facilidade do modelo automático, sugerimos o uso de Processamento Natural de Linguagem (PNL; NLP na sigla em inglês de \emph{Natural Language Processing}) como parte do processo de abstração. A ideia do uso do PNL é que, através da análise dos textos dos registros, possamos gerar, de forma automática, expressões regulares que consigam agrupar linhas de \emph{logs} similares e detetar as entidades presentes nessas linhas. Além disso, é importante que as entidades possam ser correlacionadas entre tipos de eventos diferentes. Com isso poderemos saber que dois campos em eventos  diferentes se referem à um mesmo tipo de entidade.

Além da aplicabilidade para a análise de \emph{logs}, acreditamos que o uso do processamento natural de linguagem em registros gerados por computadores pode gerar um impacto positivo na área de armazenamento de dados. Esse ganho é alcançado principalmente quando consideramos o cenário de aquisição de dados heterogêneos, necessário para um melhor desempenho dos IDSs \cite{zuech2015intrusion}.

Essa proposta é dividida da seguinte forma: no Capítulo \ref{chap:referencial} apresentamos o referencial teórico e os trabalhos relacionados; no Capítulo \ref{chap:proposta} apresentamos detalhadamente o problema que propomos tratar e mostramos nossos objetivos com essa dissertação e a metodologia que usaremos no seu desenvolvimento; por último, no Capítulo \ref{chap:cronograma} mostraremos um cronograma das atividades para o próximo ano.

\chapter{Referencial Teórico}\label{chap:referencial}

Nesta seção apresentaremos alguns trabalhos que vem sendo executados na área de abstração de \emph{logs} e as realizações atuais sobre o processamento natural de linguagem.

\section{Abstração de Logs}\title{sec:informacao}
\cite{nagappan2010abstracting} diz que, dado um conjunto de registros de eventos, ``a separação dos campos estáticos dos campos que mudam dinamicamente é abstração de \emph{logs}''. A abstração permite contornamos o problema de volume de informações, uma vez que, a grande variedade dos registros é abstraída para um número reduzido de eventos. Por exemplo, em \cite{nagappan2010abstracting} cerca de  125.000 registros podem ser abstraídas para 700 tipos de eventos.

Existem diversos trabalhos na área de abstração de \emph{logs}, como por exemplo \cite{jiang2008automated, nagappan2010abstracting, vaarandi2003data, xu2009detecting}. Esses trabalhos se baseiam, em sua maioria, no uso de técnicas estatísticas (aprendizado de máquina e de mineração de dados) para gerar os agrupamentos de \emph{logs}. Entre essas técnicas podemos citar o uso de algorítimos como \emph{frequente itemset} e algoritmos de clusterização. No entanto, nenhum desses trabalhos se preocupa em categorizar os campos variáveis de uma entrada de \emph{log}.

O trabalho de \cite{vaarandi2003data} propõe o uso de algoritmos de clusterização para agrupar linhas de \emph{logs} semelhantes. Vaarandi toma como base a ideia de que os \emph{logs} possuem poucas palavras que se repetem diversas vezes. Essas poucas palavras formam a parte estática dos registros. E por ocorrerem em conjunto elas tem um alto grau de correlação, dadas as suas posições. Com base nessa característica Vaarandi consegue grupos de palavras que formam os tipos de eventos. No entanto esse trabalho apresenta uma grande limitação: eles só conseguem detetar os tipos de eventos que ocorrem acima de uma determinada frequência, que é um parâmetro para o algoritmo. Entradas abaixo dessa frequência não conseguem ser agrupados em nenhuma evento e são colocadas em um arquivo de \emph{outliers}. Dessa forma essa abordagem se concentra no agrupamento dos itens mais frequentes dentro de um conjunto de registros.

Já o trabalho apresentado em \cite{nagappan2010abstracting}, se baseia no trabalho de \cite{vaarandi2003data}, mas o estende, permitindo a identificação de itens que ocorrem poucas vezes. A principal diferença dessa abordagem em relação a \cite{vaarandi2003data} é que o agrupamento de eventos depende do número de ocorrências das palavras em cada linha de \emph{log}, enquanto a abordagem original se concentra em detetar \emph{clusters} entre linhas diferentes. Apesar da possibilidade de melhorias em sua abordagem, não são apresentados resultados quantitativos que demonstra tais ganhos.

Uma abordagem diferente das citadas anteriormente é apresentada em \cite{jiang2008automated}. Jiang et al. usam como base a deteção de clones de código fontes, e combina técnicas heurísticas com técnicas de IA (Inteligência Artificial).  O algoritmo deles é composto de quatro etapas: (i) anonimização, por meio da remoção das partes dinâmicas dos registros com o uso de heurísticas; (ii) agrupamento de registros com base no número de itens estáticos e dinâmicos de cada linha; (iii) categorização de cada grupo em eventos destintos, através da comparação de strings; (iv) reconciliação, onde é dada a oportunidade de agrupar eventos que apresentam pouca diferença entre si e, portando, devem ser um único tipo de evento. Apesar de bons resultados apresentado no artigo, notamos que foram usadas poucos registros para a realização dos dados apresentados (somente cem). Tal número não mostra como o algoritmo se comportaria em ambientes reais. Uma outra desvantagem dessa abordagem é a necessidade de uma parametização por parte do usuário para o funcionamento do algoritmo e da necessidade da definição de heurísticas.

Uma abordagem que apresentou grande sucesso é apresentada em \cite{xu2009detecting}. Xu et al. propõem a análise do código fonte das aplicações que geram os registros, e não das entradas de \emph{log} geradas. Fazendo essa analise Xu et al. conseguem localizar todos os ``templates'' de \emph{logs} que podem ser gerados pelo sistema. Apesar do sucesso dessa abordagem, acreditamos que o acesso ao código-fonte das aplicações ainda não é ubíquo, em especial em grandes empresas, e por isso essa ainda não é uma solução viável para todos os casos.

É interessante notar que nenhum dos trabalhos acima se preocupa na identificação de entidades que compõe a parte dinâmica dos \emph{logs}. A preocupação dos autores é somente extrair tipos de eventos. No entanto, podemos ver nos excelentes resultados apresentados em \cite{xu2008mining,yen2013beehive} a importância da utilizam as entidades extraídas dos \emph{logs} para tornar a análise de problemas mais eficaz. Dessa forma, reforçamos a ideia de que a extração de entidades de forma automática é de grande importância para extração de informação do grande volume de \emph{logs} gerados diariamente.

\section{Processamento Natural de Linguagem (\emph{Natural Language Processing})}
%TODO: Detalhar o referencial de NLP
Processamento Natural de Linguagem (PNL; NLP na sigla em inglês para \emph{Natural Language Processing}) é um termo normalmente usado para descrever a função de alguns componentes de um sistema de computador capazes de analisar ou criar conteúdo em linguagem natural. O termo \emph{natural} nesse contexto indica que a linguagem que está sendo tratada é voltada para humanos, e não linguagens \emph{formais} , como notações matemáticas ou lógicas e linguagens de programação \cite{jackson2002natural}.

As técnicas de PNL, junto com técnicas de recuperação de informação \cite{manning2008introduction}, tem servido para que o grande volume de informações disponíveis hoje possam ser tratadas e consultadas, de forma a se retirar informação dos \emph{hexabytes} de dados gerados semanalmente \cite{cambria2014jumping}.

%TODO: Falar como começou a PNL e a extração de infomações/entidades

Uma das aplicações mais em alta atualmente é o uso de PNL para análise de sentimentos \cite{feldman2013techniques}. A analise de sentimentos consiste em analisar os textos gerados nas redes sociais para extrair a opinião das pessoas sobre um determinado tema, produto ou pessoa. Um subcampo dentro da análise de sentimentos é o da análise de sentimentos baseada em aspectos \cite{feldman2013techniques}. Esse tipo de análise se preocupe em identificar os aspectos (ou entidades) a que cada frase dentro de um texto se referem. Se tratarmos registros de eventos como frases (o que eles realmente são), esperamos poder usar essas técnicas de PNL para extrair os aspectos/entidades do texto.

O problema identificado na análise de sentimentos baseada em aspectos é extremamente parecido com o que apresentamos aqui. Por essa razão acreditamos que as técnicas de PNL e de análise de sentimentos podem ser úteis no contexto de abstração de \emph{logs}.

%O surgimento da Mineração de Textos (MT) foi motivado pela necessidade de se descobrir de forma semiautomática informações e conhecimento novos em textos. O uso das ferramentas de MT torna-se indispensável neste cenário, possibilitando o processamento de uma grande quantidade de textos, permitindo recuperar informações relevantes, possibilitando a extração de informação automática e o reconhecimento de padrões \cite{duque2012processo}.


Como um caso de sucesso da aplicação de técnicas de PNL para a extração de informações e identificação de entidades podemos citar o trabalho realizado em \cite{duque2012processo}. Nesse trabalho são apresentadas técnicas para extração de informações sobre tratamentos de doenças a partir de um conjunto de artigos científicos em formato digital. É interessante notar que nesse trabalho é usada uma combinação de técnicas para alcançar um melhor resultado: aprendizado de máquina, regras e dicionário. No artigo são apresentados os pontos fracos e fortes de cada técnica, e é mostrado como elas podem trabalhar em conjunto, dentro do problema estudado por Duque et al. Os resultados obtidos são compatíveis com outros trabalhos de análise de documentos, que também fazem uso do mesmo conjunto de técnicas.

%TODO: Falar dos artigos de PNL

%Em \cite{duque2012processo} é mostrado que existem, basicamente, duas abordagens para a extração de informação: abordagem baseada em regras, utilizada para identificar padrões de extração com o uso de expressões regulares; e abordagem baseada em aprendizado de máquina, que utiliza classificadores para separar ou identificar sentenças de interesse.

%O uso de técnicas de PNL \emph{Part-of-Speech} é comumente usada para identificar as classes gramaticais de uma sentença. Essa técnica combina a identificação de classes gramaticais com técnicas de aprendizado de máquina supervisionados para, após serem treinadas, poderem reconhecer as classes gramáticas das palavras.

\section{Conclusão}
Como vimos, os trabalhos que tratam da abstração de \emph{logs} se concentram em encontrar padrões de texto, e não na recuperação de entidades, como propomos. Já as técnicas de processamento natural de linguagem vem mostrando um rápido crescimento e expandindo sua aplicabilidade, dado o grande volume de dados gerados a cada dia.

\chapter{Utilização de PNL para abstração de logs}\label{chap:proposta}

Nessa seção detalharemos o funcionamento da solução que pretendemos produzir. Mostraremos a motivação para a nossa abordagem, e o detalhamento técnico, ou seja, o passo a passo, da solução que desenhamos.

Também pretendemos desenvolver uma ferramenta seja inserida dentro do fluxo de processamento de dados de uma IDS de \emph{host}. Um IDS de \emph{host} é responsável pela análise de registros de eventos e geração de alertas, caso detete alguma anomalia no ambiente analisado. Nesse cenário, o caso mais comum é que esse tipo de IDS receba dados não estruturados (\emph{logs}). 

Como explicado anteriormente, entradas não estruturadas são de difícil tratamento para sistemas de computação. Uma abordagem que visa facilitar a análise dos dados é a de ``abstração de \emph{logs}''. Ela visa abstrair eventos concretos para seu conceito mais genérico. Por exemplo, veja as seguintes entradas de \emph{log}:

\begin{verbatim}
Invalid user developer from 116.255.160.35
Invalid user root from 116.255.160.32
Invalid user antonio from 116.255.170.55
\end{verbatim}

Todas essas entradas possuem o mesmo ``formato'' : \verb|Invalid user * from *|, onde os asteríscos (\emph{*}), se referem aos campos variáveis das entradas (ou seja, os campos que podem assumir valores diferentes). Os outros campos (\emph{invalid}, \emph{user}, \emph{from}) são ditos \emph{campos estáticos}. Ou seja, as três entradas de \emph{log} acima podem ser \emph{abstraídas}, para um único \emph{tipo} de evento.

De forma mais específica podemos dizer que as linhas acima possuem um outro formato: \verb|Invalida user <user> from <ip>|, onde \verb|<user>| e \verb|<ip>| são \emph{placeholders} para o tipo de entidade a que o campo variável se refere. Ou seja, enquanto a abstração que vimos anteriormente permite identificarmos quais posições do \emph{log} são variáveis, a segunda abstração nos permite identificar a que tipo de entidade essas posições se referem.

Essas abstrações são muito úteis na comunidade da segurança da informação. A primeira abordagem permite uma redução significativa no número de eventos tratados por um analista de segurança e permite a aplicação de técnicas de mineração de dados (como a análise de sequência e análise de séries temporais). Por outro, a segunda forma de abstração oferece a capacidade de correlação de eventos, podendo identificar entidades que ocorram vários eventos. Por exemplo:

{\small
\begin{verbatim}
lightdm: pam_unix(lightdm:session): session opened for user rogerio by (uid=0)
sudo:   rogerio : TTY=pts/3 ; PWD=/home/rogerio ; USER=root ; COMMAND=/bin/ls /root
sudo: pam_unix(sudo:session): session opened for user root by rogerio(uid=0)
sudo: pam_unix(sudo:session): session closed for user root
\end{verbatim}
}

Se realizarmos a abstração dos registros acima, detetando as suas entidades, poderemos chegar aos seguintes eventos:

{\small
\begin{verbatim}
lightdm: pam_unix(lightdm:session): session opened for user <user> by (uid=<uid>)
sudo:   <user> : TTY=<tty> ; PWD=<pwd> ; USER=<user> ; COMMAND=<command>
sudo: pam_unix(sudo:session): session opened for user <user> by <user>(uid=<uid>)
sudo: pam_unix(sudo:session): session closed for user <user>
\end{verbatim}
}

Sabendo que o campo \emph{<user>} é comum a todas as entradas, um analista de segurança pode inferir que um usuário chamado \emph{rogerio} fez login no sistema e logo em seguida esse mesmo usuário executou um comando usando o \emph{sudo}. Só podemos depreender isso dessas informações pois sabemos que os campos em \emph{logs} de tipos diferentes (\emph{logs} heterogêneos) possuem uma entidade em comum (\emph{<user>}).

Apesar das óbvias vantagens da abstração de \emph{logs}, ela não é amplamente aplicada pois necessita de grande esforço manual do analista de segurança para a geração das regras de abstração. Essa atividade está sujeita a falhas e pode ser comprometida pela mudança da estrutura dos \emph{logs} gerados pelos sistemas (fora do controle do analista).

A identificação de entidades também é importante para aplicação de técnicas de deteção de intrusão (onde imaginamos que nossa solução será inserida). Por exemplo, a técnica de deteção de intrusão chamada de deteção de anomalias, não apresenta desempenho satisfatório quando usamos somente as informações textuais para procurar por ataques. O trabalho apresentado em \cite{li2013automatic} mostra isso.

Por outro lado, o trabalho apresentado em \cite{yen2013beehive} mostra bons resultados na deteção de intrusão através da análise de alguns tipos específicos de \emph{logs}, quando é feito um pré-processamento dos dados e deles é retirado um conjunto ``interessante'' de informações. Esse mesmo ganho é comprovado em \cite{xu2009detecting}, onde foi desenvolvido um método automático de retirada de informações semânticas dos \emph{logs}. No entanto, a técnica usada em Xu et al. envolve a análise do código fonte da aplicação que gera os \emph{logs}. Em ambientes de grandes empresas nem sempre os softwares usados são de código aberto, o que torna impossível de ser aplicada a técnica de Xu et al..

\section{Processamento Natural de Linguagem e extração de entidades}
Para superar as dificuldades que apresentamos na seção anterior, são necessários mecanismos que permitam a caracterização automática de entidades. No entanto, os trabalhos acadêmicos que encontramos se concentram em automatizar somente o primeiro caso de abstração que mostramos anteriormente: agrupar tipos parecidos de \emph{logs}, mas sem identificar a quais entidades as partes variáveis se referem \cite{vaarandi2003data, nagappan2010abstracting}.

Nesse sentido o uso das técnicas de PNL pode trazer ganhos para a deteção de entidades. Podemos usar o PNL para encontrar o significado de uma frase (positivo ou negativo) e tentar encontrar as entidades referenciadas em uma dada linha de \emph{log} (usuário, IP de origem, sistema impactado, etc). Podemos ainda, correlacionar automaticamente o mesmo tipo de entidade em diferentes \emph{logs} (mesmo entre registros de aplicações diferentes).  Nesse sentido, temos como referência o trabalho apresentado em \cite{duque2012processo}.

Além disso, acreditamos que as técnicas de PNL podem nos ajudar a melhor classificar as entidades. Por exemplo, observe as entradas de log abaixo:

{\small
	\begin{verbatim}
	refused connect from 192.168.0.1:1231 to procedure ypproc_domain_nonack
	connect to 192.168.0.1:25: Connection timed out
	\end{verbatim}
}

Enquanto a entidade \emph{192.168.0.1} aparece nas duas entradas de logs (e nos dois casos ela é um IP), ela possui contextos diferentes. No primeiro caso, a entidade é um IP de origem (isto é, está originando a ação). No segundo caso, ela é um IP de destino (recebe uma ação). Esse tipo de diferença é importante durante o processo de análise de \emph{logs} e pode servir de insumo para tomada de decisões. Nesse caso, o tipo da entidade é indicada pelo texto no \emph{log}: a precedência do \emph{IP} pelas palavras \emph{from} e \emph{to}.

Os avanços que esperamos alcançar com o desenvolvimento de nosso trabalho, também podem gerar impactos no processo de consolidação de dados. Um desafio presente não só nos IDS, mas também para qualquer sistema de \emph{Big Data} \cite{zuech2015intrusion}. Em especial, se a classificação automática de entidades puder ser feita de forma \emph{online} (durante a transmissão de dados), podemos começar a trabalhar de forma muito mais rápida e com menor tempo de reação, para novos ataques, por meio da integração contínua de dados.


\section{Objetivos}
O objetivo geral deste trabalho é estudar técnicas de PNL que possam permitir a identificação de entidades dentro dos \emph{logs}.

Como objetivos específicos podemos citar:
\begin{itemize}
	\item Estudar as várias soluções de abstração de \emph{logs} e de PNL, dentro da comunidade acadêmica;

	\item Pesquisar ferramentas que implementem algoritmos de PNL e que possivelmente possam ser utilizadas em nosso trabalho;

	\item Definir um algortimo para a abstração de \emph{logs} que permita a identificação de entidades;

	\item Implementar um produto de software (uma ferramenta) usando o algortimo definido;

	\item Definir uma Política de Avaliação de Performance, para podermos analisar os resultados de nosso trabalho em comparação com os já existentes na literatura;

\end{itemize}

Com essa abordagem nós esperamos alcançar alguns objetivos que não identificamos em nenhum outro trabalho encontrado até o momento na literatura:

\begin{itemize}
	\item Definir uma política de avaliação de desemepnho, para medir a capacidade de abstração de \emph{logs}, que pode ser usada para avaliar novas ferramentas;
	\item Definir uma nova forma de abstração de \emph{logs}, que consiga detetar o tipo de entidade presente nos \emph{logs};
\end{itemize}

\section{Metodologia}

%
%
%\section{Proposta de Implementação}\label{sec:implementacao}
%Dado o exposto anteriormente, o nosso objetivo com esse trabalho é um algoritmo, e implementar um solução de software, que permita a deteção de padrões em \emph{logs} de sistemas. A principal diferença de nossa abordagem para as que existem hoje em dia, é que não queremos somente agrupar \emph{logs} similares, como em \cite{vaarandi2003data}, mas também detectar ``entidades'' dentro dos \emph{logs}, através de técnicas de PNL.
%Nós visualizamos nossa solução sendo usada como a primeira etapa de processamento para o recebimento de \emph{logs}, de forma que sua saída (os \emph{logs}, agrupadas e com suas entidades categorizadas), possa ser armazenado para posterior consumo por humanos ou por outras soluções de software.
%Durante o desenvolvimento do nosso projeto, também será elaborada um métrica para avaliar o desempenho de nossa solução, quando comparada com as demais.
%
%

A nossa metodologia de trabalho visa uma abordagem incremental, chegando a solução de problemas complexos por meio da sua quebra em componentes mais simples. A primeira etapa da nossa abordagem é a extração de ``eventos'' a partir \emph{logs} de um único programa (possivelmente utilizando uma das técnicas já disponíveis na literatura).

Em seguida, numa segunda etapa, queremos extrair as entidades que compõem os eventos que identificamos. Pretendemos que essa abstração permita correlacionar essas entidades. Isto é, pretende-se saber quais campos dinâmicos em eventos destintos se referem à mesma entidade. Essa é uma das nossas principais contribuições, pois até o momento não encontramos nenhum trabalho que faça esse processamento de forma automática.

A seguir, numa terceira etapa, queremos estender nossa técnica e confirmar quais entidades pode ser correlacionadas em eventos gerados por aplicações diferentes.

Em todas as três etapas iremos, quando possível, comparar nossos resultados com os resultados obtidos em outros trabalhos, por meio de nossa metodologia de avaliação.

Em paralelo, também durante as três etapas supracitadas, compartilharemos os resultados encontrados com a comunidade acadêmica, por meio da publicação de artigos em congressos com Qualis e da elaboração de uma dissertação de Mestrado.

\subsection{Análise de desempenho do algoritmo}

Um dos objetivos específicos do nosso trabalho é definir uma política de avaliação de desempenho, da classificação de entidades. Nossa intenção é podermos identificar não só como o nosso trabalho se coloca em relação a outros já realizados, mas também para podermos detetar melhorias no desenvolvimento de nossa solução.

Abaixo seguem algumas das características que pretendemos implementar para a métrica de análise de desempenho que desejamos criar:

\begin{itemize}
	\item A métrica deve ser objetiva, isto é, ela deve produzir um valor quantitativo;
	\item Devemos conseguir comparar os resultados de soluções já existentes;
\end{itemize}

\section{Recursos adicionais}
Além do embasamento teórico necessário para a realização deste trabalho de pesquisa, também necessitamos de algum referencial técnico (como implementações de algoritmos já conhecidos). Nesta seção, falaremos sobre as bibliotecas e linguagens de programação que pretendemos usar. Além disso, ao final da seção comentaremos sobre quais dados usaremos para análise.

\subsection{Bibliotecas de Processamento Natural de Linguagem}

Nosso objetivo nesse trabalho não é desenvolver um novo paradigma para o PNL. Por isso, iremos fazer uso de bibliotecas de programação já existentes. Tais bibliotecas devem fornecer as técnicas que pretendemos utilizar. Para isso, inicialmente planejamos usar a biblioteca NLTK (Ferramentas de Linguagem Natural, na sigla em inglês para \emph{Natural Language Tool Kit}) \cite{bird2009natural}. Essa biblioteca funciona em conjunto com a linguagem de programação Python.

A escolha dessa biblioteca foi feita levando em consideração os seguintes pontos:

\begin{itemize}
	\item Biblioteca distribuída livremente (sob licença \emph{Open-Source}), o que facilita a reprodutibilidade do trabalho;
	\item Documentação ampla, facilitando seu uso;
	\item Utilização da linguagem Python (também de uso de domínio amplo, além de ter sudo utilizada em outras atividades do mestrando);
\end{itemize}

Além disso, a linguagem Python possui mais algumas vantagens, que a tornam interessante para o desenvolvimento de uma solução de software completa, a saber:

\begin{itemize}
	\item Python possui suporte a outras bibliotecas que dão suporte a diversas técnicas de aprendizado de máquina que podem ser necessárias durante o desenvolvimento do trabalho, como por exemplo a biblioteca scikit-learn \cite{pedregosa2008scikitlearn};
	\item Possui suporte de conectividade a banco de dados;
	\item Proporciona suporte ao desenvolvimento de aplicações Web;
	\item Possui facilidade de conectividade com outras linguagens de programação (\emph{bindings});
\end{itemize}

\subsection{Repositório de logs}

Um ponto importante para a realização de nosso trabalho são os \emph{logs} que iremos analisar e usar para desenvolver nossa solução. Pelo que percebemos até o momento, todos os outros trabalhos que focaram em técnicas de abstração de \emph{logs} o fizeram usando dados de ambientes de produção que não estão disponíveis publicamente.

Para nosso estudo poderíamos usar um pequeno volume de dados de um computador local, ou gerar dados a partir de um ambiente simulado. No entanto, acreditamos que essas soluções não reproduzam a complexidade existente em um ambiente de produção.

A disponibilização de \emph{logs} de forma pública não é uma prática comum, pois pode gerar vazamento de informações. A maioria dos registros que são disponibilizados publicamente são de ambientes simulados, o que pode não refletir o ambiente de produção de uma empresa.

Para o nosso trabalho iremos utilizar o repositório de \emph{logs} \url{http://www.secrepo.com/} que é mantido por membros da comunidade de segurança da informação. No decorrer de nosso trabalho iremos identificar quais \emph{logs} desse repositório melhor se adequarão ao nosso estudo. Isso pode garantir que tenhamos dados que refletem um ambiente existente na indústria, e também permite a reprodutibilidade de nosso trabalho, já que os dados disponíveis no referido site são de domínio público.

\chapter{Cronograma}\label{chap:cronograma}
O desenvolvimento deste trabalho foi definido da seguinte forma:

\begin{enumerate}
	\item \label{rev-bibli} Revisão bibliográfica;
	\item \label{esc-base} Escolha de base de dados para análise;
	\item \label{imp-outras} Coleta/Implementação de outras soluções de abstração de \emph{logs};
	\item \label{def-pol} Definição de politica de análise de desempenho;
	\item \label{est-nltk} Estudo da biblioteca NLTK;
	\item \label{algo-abs} Definição de algorítimo para abstração de \emph{logs};
	\item \label{algo-clas} Definição de algorítimo para classificação de entidades;
	\item \label{imp-sol} Implementação ferramenta: da solução de software;
	\item \label{ava-des} Avaliação de desempenho da solução implementada;
	\item \label{esc-dis} Escrita da Dissertação;
	\item \label{pub-art} Publicação de artigos;
\end{enumerate}

\begin{table}[!htbp]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		&\multicolumn{5}{c|}{2016}&\multicolumn{5}{c|}{2017}\\
		\hline
		&AGO&SET&OUT&NOV&DEZ&JAN&FEV&MAR&ABR&MAI\\
		\hline
		\ref{rev-bibli}& \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet \\
		\hline
		\ref{esc-base}& \textbullet & \textbullet &&&&&&&&\\
		\hline
		\ref{imp-outras}& \textbullet &\textbullet & \textbullet &&&&&&&\\
		\hline
		\ref{def-pol}& &&&\textbullet &\textbullet &&&&&\\
		\hline
		\ref{est-nltk}&&\textbullet &\textbullet &\textbullet &\textbullet &&&&&\\
		\hline
		\ref{algo-abs}& &&\textbullet&\textbullet&\textbullet&&&&&\\
		\hline
		\ref{algo-clas}& &&&\textbullet&\textbullet&\textbullet&\textbullet&&&\\
		\hline
		\ref{imp-sol}&&&&&&\textbullet&\textbullet&\textbullet&&\\
		\hline
		\ref{ava-des}&&&&&&&\textbullet&\textbullet&\textbullet&\textbullet\\
		\hline
		\ref{esc-dis}&&&&&&\textbullet&\textbullet&\textbullet&\textbullet&\textbullet\\
		\hline
		\ref{pub-art}& & & \textbullet & \textbullet & \textbullet & & \textbullet & \textbullet & &  \\
		\hline
	\end{tabular}
\end{table}

%\chapter{Conclusão}\label{chap:conclusao}
%Nessa proposta apresentamos a nossa ideia para implementação de uma solução de abstração de \emph{logs} com o uso de técnicas de processamento natural de linguagem.

%Durante essa proposta apresentamos a lacuna existente hoje nas pesquisas de abstração de \emph{logs}, onde não identificamos nenhuma solução que possa realizar a extração de entidades dos \emph{logs} (que mostramos ser de grande importância, para o analista de segurança, e para a implementação de técnicas de deteção de intrusão). Também mostramos como acreditamos que as técnicas de processamento natural de linguagem pode ajudar na identificação de entidades (e de seus contextos).

%Apresentamos também os dados e as tecnologias que pretendemos usar durante o desenvolvimento do nosso trabalho (lignuagem de programação Python, bibliotecas NLTK e scikit-learn, e o repositório de \emph{logs} \url{http://www.secrepo.com}{SecRepo}).

%Mostramos a necessidade da abstração de \emph{logs} (para facilitar o trabalho dos analistas de segurança e também de oferecer ao mesmo novos mecanismos de análise), e como a mesma ainda está sendo feita, em grande parte de forma manual.

% ---
% Finaliza a parte no bookmark do PDF
% para que se inicie o bookmark na raiz
% e adiciona espaço de parte no Sumário
% ---
\phantompart

% ---
% Conclusão
% ---
%\chapter*[Considerações finais]{Considerações finais}
%\addcontentsline{toc}{chapter}{Considerações finais}

% ----------------------------------------------------------
% - ELEMENTOS PÓS-TEXTUAIS
% ----------------------------------------------------------
\postextual

% ----------------------------------------------------------
% Referências bibliográficas
% ----------------------------------------------------------
\bibliography{bibliografia}

% ----------------------------------------------------------
% Glossário
% ----------------------------------------------------------
%
% Consulte o manual da classe abntex2 para orientações sobre o glossário.
%
%\glossar

% ----------------------------------------------------------
% Apêndices
% ----------------------------------------------------------

%---------------------------------------------------------------------
% -INDICE REMISSIVO
%---------------------------------------------------------------------

\phantompart

\printindex


\end{document}
