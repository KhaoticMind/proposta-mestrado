% !TeX spellcheck = pt_br

%% abtex2-modelo-projeto-pesquisa.tex, v-1.9.5 laurocesar
%% Copyright 2012-2015 by abnTeX2 group at http://www.abntex.net.br/ 
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on 
%% http://www.abntex.net.br/
%%
%% This work consists of the files abntex2-modelo-projeto-pesquisa.tex
%% and abntex2-modelo-references.bib
%%

% ------------------------------------------------------------------------
% ------------------------------------------------------------------------
% - abnTeX2: Modelo de Projeto de pesquisa em conformidade com 
% - ABNT NBR 15287:2011 Informação e documentação - Projeto de pesquisa -
% - Apresentação 
% ------------------------------------------------------------------------ 
% ------------------------------------------------------------------------

\documentclass[
	% -- opções da classe memoir --
	12pt,				% tamanho da fonte
	openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
	twoside,			% para impressão em verso e anverso. Oposto a oneside
	a4paper,			% tamanho do papel. 
	% -- opções da classe abntex2 --
	%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
	%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
	%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
	%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
	% -- opções do pacote babel --
	english,			% idioma adicional para hifenização
%	french,				% idioma adicional para hifenização
	spanish,			% idioma adicional para hifenização
	brazil,				% o último idioma é o principal do documento
	]{abntex2}

% ---
% -PACOTES
% ---

% ---
% Pacotes fundamentais 
% ---
\usepackage{lmodern}			% Usa a fonte Latin Modern
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{microtype} 			% para melhorias de justificação
% ---

% ---
% Pacotes adicionais, usados apenas no âmbito do Modelo Canônico do abnteX2
% ---
\usepackage{lipsum}				% para geração de dummy text
% ---

% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT

% --- 
% -CONFIGURAÇÕES DE PACOTES
% --- 

% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		Nenhuma citação no texto.%
	\or
		Citado na página #2.%
	\else
		Citado #1 vezes nas páginas #2.%
	\fi}%
% ---

% ---
% Informações de dados para CAPA e FOLHA DE ROSTO
% ---
\titulo{Utilização de processamento natural de linguagem para abstração de logs}
\autor{Antonio Augusto Oliveira Viana Santos}
\local{Brasil}
\data{02-2016}
\instituicao{%
  Universidade Federal de Sergipe -- UFS
  \par
  PROCC - Programa de Pós-graduação em Ciência da Computação}
\tipotrabalho{Proposta de Mestrado}
% O preambulo deve conter o tipo do trabalho, o objetivo, 
% o nome da instituição e a área de concentração 
\preambulo{Proposta de Mestrado para PROCC}
% ---

% ---
% Configurações de aparência do PDF final

% alterando o aspecto da cor azul
\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
\makeatletter
\hypersetup{
     	%pagebackref=true,
		pdftitle={\@title}, 
		pdfauthor={\@author},
    	pdfsubject={\imprimirpreambulo},
	    pdfcreator={LaTeX with abnTeX2},
		pdfkeywords={abnt}{latex}{abntex}{abntex2}{projeto de pesquisa}, 
		colorlinks=true,       		% false: boxed links; true: colored links
    	linkcolor=blue,          	% color of internal links
    	citecolor=blue,        		% color of links to bibliography
    	filecolor=magenta,      		% color of file links
		urlcolor=blue,
		bookmarksdepth=4
}
\makeatother
% --- 

% --- 
% Espaçamentos entre linhas e parágrafos 
% --- 

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

% ---
% compila o indice
% ---
\makeindex
% ---

% ----
% Início do documento
% ----
\begin{document}

% Seleciona o idioma do documento (conforme pacotes do babel)
%\selectlanguage{english}
\selectlanguage{brazil}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing 

% ----------------------------------------------------------
% -ELEMENTOS PRÉ-TEXTUAIS
% ----------------------------------------------------------
% \pretextual

% ---
% Capa
% ---
\imprimircapa
% ---

% ---
% Folha de rosto
% ---
\imprimirfolhaderosto
% ---

% ---
% -NOTA DA ABNT NBR 15287:2011, p. 4:
%  ``Se exigido pela entidade, apresentar os dados curriculares do autor em
%     folha ou página distinta após a folha de rosto.''
% ---

% ---
% inserir lista de ilustrações
% ---
\pdfbookmark[0]{\listfigurename}{lof}
\listoffigures*
\cleardoublepage
% ---

% ---
% inserir lista de tabelas
% ---
%\pdfbookmark[0]{\listtablename}{lot}
%\listoftables*
%\cleardoublepage
% ---

% ---
% inserir lista de abreviaturas e siglas
% ---
%\begin{siglas}
%  \item[ABNT] Associação Brasileira de Normas Técnicas
%  \item[abnTeX] ABsurdas Normas para TeX
%\end{siglas}
% ---

% ---
% inserir lista de símbolos
% ---
%\begin{simbolos}
%  \item[$ \Gamma $] Letra grega Gama
%  \item[$ \Lambda $] Lambda
%  \item[$ \zeta $] Letra grega minúscula zeta
%  \item[$ \in $] Pertence
%\end{simbolos}
% ---

% ---
% inserir o sumario
% ---
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\cleardoublepage
% ---


% ----------------------------------------------------------
% -ELEMENTOS TEXTUAIS
% ----------------------------------------------------------
\textual

% ----------------------------------------------------------
% Introdução
% ----------------------------------------------------------
\chapter[Contextualização]{Contextualização}

Durante os últimos anos, a segurança da informação tem sido uma grande preocupação para todos os usuários da Internet, devido aos diversos ataques que vem sendo perpetrados por meio dessa rede global. Por exemplo, segundo dados do CERT.br, o número total de notificações de incidentes de segurança superou a marca de um milhão em 2014, um aumento de mais de 200\% em relação ao ano anterior \cite{incidentes2015incidentes}. Para tentar mitigar esses incidentes a comunidade de segurança da informação vem desenvolvendo ferramentas e padrões para tornar os sistemas de informação mais seguros, de modo a dificultar o acesso a informações valiosas à pessoas não autorizadas. No entanto, os profissionais da área concordam em afirmar que não existe um sistema de segurança perfeito, apesar das técnicas e aplicações desenvolvidas \cite{dua2011data}.

Por esse motivo, as entidades que precisam de mais segurança optam por implantar Sistemas de Detecção de Intrusão (IDS, na sigla em inglês). O objetivo desses sistemas não é evitar que pessoas não autorizadas tenham acesso aos sistemas e/ou dados, mas detectar quando tais tentativas ocorram. Os primeiros trabalhos sobre IDSs são da década de 80 \cite{anderson1980computer, denning1987intrusion} e a partir de então vários trabalhos tem sido realizados para garantir que os IDSs possam sempre atender às demandas dos ambientes onde estão inseridos. Um dos principais desafios enfrentados por esses sistemas é o grande volume de dados que devem ser analisados, processados e exibidos de forma intuitiva para o usuário final \cite{big2013big, nassar2013secure}.

Além disso, estas tentativas de invasão através da Internet ou de outra rede de computadores, estão se tornando mais elaborados devido à constante criação de novos ataques ou de variantes de ataques existentes \cite{zuech2015intrusion}. Dessa maneira acredita-se que o futuro da detecção de intrusão depende de melhorias na detecção baseada em anomalias, visto que a detecção baseada em assinaturas oferece pouca capacidade de lidar com a velocidade com que novos ataques são gerados.

Para superar esse desafio, a comunidade acadêmica tem empreendido muitos esforços na busca de melhores arquiteturas para solução de detecção de intrusão, buscando, inclusive, inspiração (e técnicas) que obtiveram sucesso em outras áreas da computação. No entanto, para criar uma solução de IDS realmente inteligente, isto é, que possa detectar, de forma autônoma, vários ataques e que ofereça \emph{feedback} relevante para os seus usuários, devemos combinar várias tecnologias atualmente disponíveis (traçando um paralelo com \cite{schales2011stream}).

Com base nessas informações, durante uma disciplina do primeiro ano do mestrado, foi feita uma revisão da literatura conduzida (ainda a ser publicada), onde revisamos vários trabalhos que vem sendo desenvolvidos na área de detecção de intrusão usando diversas técnicas que julgamos promissoras (quais sejam: aprendizado de máquina, sistemas multiagentes, sistemas de data \emph{warehouse}, visualização de dados, detecção de intrusão baseada em regras e ontologias), e identificamos que ainda existem diversos pontos de melhoria (nas soluções individuais e nas suas combinações) a serem perseguidos pela comunidade.

Um ponto que nos chamou atenção durante essa revisão foi o uso de técnicas de aprendizado de máquina, e a variedade de possíveis aplicações que os pesquisadores têm encontrado dentro da área de detecção de intrusão (existe, inclusive, um grupo dedicado ao uso de técnicas de aprendizado de máquina para segurança da informação - \url{http://www.mlsecproject.org/}). 

Um dos campos onde identificamos potenciais ganhos com o uso de técnicas de aprendizado de máquinas, é o de analise de \emph{logs}, que detalharemos a seguir.

\section{Analise de logs}

A detecção de invasão através da análise de \emph{logs} de sistema é importante, pois é usada para \emph{compliance} de empresas, sendo requisito de padrões de segurança como o PCI DSS e a lei Sarbanes-Oxley \cite{prakhar2012log}). O padrão para a geração de \emph{logs} em ambientes UNIX\texttrademark (amplamente usado em ambientes de servidores \cite{w3techs-osusage}) é o \emph{syslog}. As mensagens de \emph{log} do formato syslog são em texto plano e, em sua maioria, escritas em linguagem corrente. O uso de linguagem corrente torna esses \emph{logs} fáceis para interpretar por humanos, mas difíceis de serem analisados por máquinas. O uso de técnicas de processamento natural de linguagem - uma sub-área do aprendizado de máquina - pode ser usada para extrair informações das entradas de logs usando técnicas de extração e recuperação de informação \cite{bird2009natural,manning2008introduction}.

A análise de \emph{logs} hoje em dia pode ser feita de forma manual ou automática. A primeira solução é feita gerando padrões de texto de forma manual através do uso de expressões regulares - \emph{regex}, de forma que é possível a extração das ``entidades''\footnote{Por entidades nos referimos aos hosts, ips, usuários, etc, que são referidos em uma linha de log} que compõe uma linha de \emph{log}. Já nas técnicas automáticas linhas similares são agrupadas  (com variados graus de sucesso) de forma a produzir um único ``tipo de evento``, que pode ser mais facilmente analisado, mas sem conseguir discernir os componentes de cada linha.

A ideia do uso da linguagem natural é permitir a geração automática de expressões regulares que consigam, não só agrupar linhas de \emph{logs} similares, mas que também possam detectar as entidades presentes nessas linhas. Além disso é importante que as entidades possam ser correlacionadas entre tipos de eventos diferentes (isto é, saber que dois campos em entradas de \emph{logs} diferentes se referem à entidade usuário).

Além da aplicabilidade para a análise de \emph{logs}, acreditamos que o uso do processamento natural de linguagem em registros gerados por computadores pode gerar um impacto positivo na área de armazenamento de dados. Esse ganho é alcançado principalmente quando consideramos o cenário de aquisição de dados heterogêneos, necessário para um melhor desempenho dos IDSs \cite{zuech2015intrusion}.

Essa proposta é dividida da seguinte forma: no Capítulo \ref{chap:referencial} apresentamos o referencial teórico de suporte ao nosso trabalho; no Capítulo \ref{chap:proposta} apresentaremos nossa proposta e seus impactos, inicialmente, em alto nível, e a seguir serão mostrados alguns dos detalhes técnicos do que esperamos alcançar com nosso trabalho; por último, no Capítulo \ref{chap:cronograma} mostraremos um cronograma das nossas atividades para o próximo ano.

\subsection{Objetivos}

O objetivo geral deste trabalho é o de estudar técnicas de Processamento Natural de Linguagem (PNL; NLP na sigla em inglês) que possam ser de valia para a abstração de \emph{logs}, permitindo a identificação de entidades dentro dos \emph{logs}, de forma a podermos gerar melhores abstrações dos \emph{logs}.

Como objetivos específicos podemos citar:
\begin{itemize}
	\item Estudar as várias soluções de abstração de \emph{logs} e de processamento natural de linguagem, dentro da comunidade acadêmica;

	\item Pesquisar ferramentas que implementem algoritmos de NLP e que possivelmente possam ser utilizadas em nosso trabalho (especificamente as bibliotecas NLTK \cite{bird2009natural} e scikit-learn \cite{pedregosa2008scikitlearn}.)
	
	\item Definir uma Política de Avaliação, para podermos identificar melhoras no nosso trabalho, e poder gerarmos comparações com outros trabalhos publicados;
	
	\item Implementar um produto de software usando as técnicas de NLP estudadas acima, para geração de abstrações de \emph{logs} que possam detectar as entidades que fazem o compõe;
	
	\item Analisar desempenho da solução implementada usando a Política de Avaliação a ser definida para verificar ganhos da nossa solução;
		
\end{itemize}

Com essa abordagem nos esperamos alcançar alguns objetivos que não encontramos em nenhum outro ponto da literatura:

\begin{itemize}
	\item Definir uma política de avaliação da capacidade de abstração de \emph{logs}, que pode ser usado para avaliar novas ferramentas;
	\item Definir uma nova forma de abstração de \emph{logs}, que consegue detectar o tipo de entidade presente nos \emph{logs};
\end{itemize}

\subsection{Trabalhos relacionados}
Existem diversos trabalhos na área de abstração de \emph{logs} (a técnica de agrupar eventos similares), como por exemplo \cite{jian2008automated, nagappan2010abstracting, vaarandi2003data}. Esses trabalhos se baseiam, em sua maioria, no uso de técnicas estatísticas (aprendizado de máquina e de mineração de dados) para gerar os agrupamentos de \emph{logs}. Entre essas técnicas podemos citar o uso de algorítimos como \emph{frequente itemset} e algorítimos de clusterização. Nenhum desses trabalhos se preocupa em categorizar os campos variáveis de uma entrada de \emph{log}, chegando, até mesmo, a normalizá-las (anonimizar).

É importante notar que existem outras abordagens para a abstração de \emph{logs}, como a apresentada em \emph{xu2009detecting}, onde a abstração é feita a partir do código fonte da aplicação, e não das entradas de \emph{log} geradas. Enquanto essa abordagem obteve grande sucesso no trabalho apresentado, acreditamos que o acesso ao código-fonte das aplicações ainda não é ubíqua, em especial em grandes empresas, e por isso ainda não é uma solução viável para todos os casos. 

\section{Metodologia}

A nossa metodologia de trabalho visa uma abordagem incremental, chegando a solução de problemas complexos através da sua quebra em componentes mais simples.

O primeiro objetivo de nossa abordagem é a extração de ``eventos'' a partir \emph{logs} de um único programa (possivelmente utilizando uma das técnicas já disponíveis). Em seguida queremos extrair, desse único tipo de evento, as entidades que o compõe, de forma a correlaciona-las (isto é, saber que dois nomes, referem-se a usuários, por exemplo). Esse é uma de nossas principais contribuições, por não encontramos nenhum trabalho que faça esse tipo de geração de forma automática.

A seguir queremos correlacionar as entidades através de tipos de eventos diferentes, ou seja, saber quais campos, de diferentes tipos de \emph{logs}, se referem a um usuário ou a um \emph{host}, por exemplo.

Em todas as etapas iremos, quando possível, comparar nossas resultados com os obtidos em outros trabalhos, através de nossa metodologia de avaliação.

A última etapa do nosso trabalho é compartilhar os resultados encontrados com a comunidade acadêmica, através da publicação de artigos em congressos com Qualis, e  da elaboração de uma dissertação de mestrado, ou da compilação de artigos publicados;

\subsection{Analise de desempenho}

Um dos objetivos do nosso trabalho é definir uma política de avaliação de desempenho, para podermos identificar, não só como nosso trabalho se coloca em relação a outros já realizados, como também para podermos detectar melhorias no desenvolvimento de nossa solução.

Abaixo algumas das características que queremos para a nossa métrica de análise de desempenho:

\begin{itemize}
	\item Ela deve ser objetiva, isto é, ela deve produzir um valor quantitativo;
	\item Devemos conseguir comparar os resultados de soluções já existentes, e não só a que estamos desenvolvendo;
\end{itemize}

\chapter{Referencial Teórico}\label{chap:referencial}

Nesta seção apresentaremos alguns trabalhos que vem sendo executados na área de detecção de intrusões com uso de técnicas de aprendizado de máquina, trabalhos relacionados a abstração de \emph{logs}, e as realizações atuais sobre o processamento natural de linguagem. No tocante ao uso de aprendizado de máquina, vê-se que os trabalhos não se restringem somente à detecção de anomalias, mas possuem também várias outras aplicações. Quanto à abstração de \emph{logs}, vemos que os trabalhos se concentram em encontrar padrões de texto, e não na recuperação de entidades, como propomos. Por último, as técnicas de processamento natural de linguagem vem mostrando um rápido crescimento e expandindo sua aplicabilidade.

\section{Aprendizado de máquina}\title{sec:aprendizado_de_maquina}
O uso de técnicas de aprendizado de máquina começou a ser explorada na área de detecção de intrusões focando em melhorias na detecção de anomalias em IDSs, visto que a maioria dos sistemas hoje usam técnicas de detecção por assinatura, o que restringe sua ação para detecção de variações de ataques existentes, ou mesmo de novos ataques. Essas técnicas, e a mineração de dados, de forma geral, tem apresentado bons resultados nesse sentido \cite{dua2011data, yen2013beehive, zomlot2013aiding, ganapathy2012intelligent, li2013automatic, joseph2012machine}.

Em \cite{yen2013beehive} é apresentado um trabalho com o uso de técnicas de clusterização (uma variação do algoritmo K-means\cite{ball1967clustering}), para a detecção de possíveis infecções de \emph{malwares} em sistemas conectados à Internet através da análise de \emph{logs} de \emph{proxies}, servidores de VPN, DHCP e controladores de domínio Microsoft Windows \texttrademark. Os resultados apresentados nesse trabalho são extremamente relevantes e encorajadores, por duas razões: i) o sistema conseguiu identificar mais de 750 incidentes, dos quais apenas 8 haviam sido detectados anteriormente por sistemas de segurança já usados na empresa onde o estudo foi realizado; ii) o trabalho é feito com um volume grande de informações (cerca de 1 Tb/dia), claramente um desafio relacionado à \emph{Big Data}. No trabalho são mostradas técnicas para a redução do volume de dados e para a seleção de \emph{features} para análise.

Ainda no campo de detecção de anomalias, em \cite{li2013automatic} bons resultados são alcançados através da combinação de técnicas diferentes de aprendizado de máquina. Nesse trabalho são apresentados dois algoritmos aplicados sequencialmente: o primeiro usado para criar meta-eventos, e o segundo para classificação, usando esses meta-eventos (ao invés dos eventos em si). Nesse trabalho são usados os algoritmos SOM \cite{kohonen1989self}, para gerar os meta-eventos e o DBSCAN \cite{ester1996density}, para a agregação dos meta-eventos.

Mas, além da detecção de anomalias, outro campo que tem recebido muita pesquisa na academia é o uso de mineração de dados para lidar com o grande volume de alertas gerados pelos IDSs baseados em regras usados atualmente. O trabalho apresentado em \cite{zomlot2013aiding}, por exemplo, utiliza a aprendizagem de máquina para tentar priorizar os incidentes: um modelo aprende a opinião de analistas sobre a prioridade dos alertas, e esse conhecimento, posteriormente, é replicado pelo sistema, priorizando automaticamente os alertas.

Outros trabalhos tentam preencher a lacuna na correlação de eventos de segurança, de forma a identificar a relação entre eventos distintos \cite{smith2008using, stroeh2013approach}.

\section{Abstração de logs}\title{sec:informacao}
\cite{nagappan2010abstracting} diz que, dado um conjunto de entradas de \emph{logs}, ``a separação dos campos estáticos dos campos que mudam dinamicamente é abstração de \emph{logs}'', ou seja, abstração de \emph{logs} é a técnica de agrupar \emph{logs} do mesmo tipo, de forma que, ao final, tenhamos \emph{templates} desses \emph{logs}, de forma mais genérica possível, e, possivelmente, um quantitativo de quantas vezes cada tipo de \emph{log} ocorreu.

Note que incidentalmente a separação dos campos estáticos dos dinâmicos, normalmente, corresponde a um \emph{template} que pode ser encontrado no código fonte do programa. 

Tento isso em vista \cite{xu2009detecting}, usa uma técnica de análise análise de código fonte para extração de \emph{templates} para abstração de logs. Enquanto o resultado obtido por eles é motivador acreditamos que a necessidade de acesos ao código é um fator limitante, pois diversas empresas ainda não estão prontas para adotar software livre ou desenvolver soluções caseiras, para todas as suas necessidades de software.

\section{Processamento natural de linguagem}
%TODO: Detalhar o referencial de NLP
A área de mineração de textos, em especial a área de extração de informações, vem realizando trabalhos similares ao nosso, mas em um outro contexto \cite{duque2012processo, matos2010environment}.

\cite{bird2009natural}

\section{Recursos adicionais}
Além do embasamento teórico necessário para a realização desse trabalho, também necessitamos de algum referencial técnico (como implementações de algorítimos já conhecidos). Nessa seção falaremos sobre as bibliotecas e linguagens de programação que pretendemos usar. Além disso, ao final, comentaremos sobre quais dados usaremos para análise.

\subsection{Bibliotecas de processamento natural de linguagem}

Nosso objetivo nesse trabalho não é desenvolver um novo paradigma para o processamento natural de linguagem. Por isso iremos fazer uso de bibliotecas de programação já existentes, que forneçam suporte as técnicas que pretendemos utilizar. Para isso planejamos usar a biblioteca NLTK (Ferramentas de Linguagem Natural, na sigla em inglês) \cite{bird2009natural}. Essa biblioteca funciona em conjunto com a linguagem de programação Python.

A escolha dessa biblioteca foi feita levando em consideração os seguintes pontos:

\begin{itemize}
	\item Biblioteca distribuída livremente (sob licença Open-Source), o que facilita a reprodutibilidade do trabalho;
	\item Documentação ampla, facilitando seu uso;
	\item Utilização da linguagem Python (de domínio do mestrando);
\end{itemize}

Além disso, a linguagem Python, por si só, possui mais algumas vantagens, que a tornam interessante para o desenvolvimento de uma solução de software completa:

\begin{itemize}
	\item Outras bibliotecas que dão suporte a diversas técnicas de aprendizado de máquina (que podem ser necessárias durante o desenvolvimento do trabalho);
	\item Suporte para a criação de uma solução de software completa (suporte à conectividade à banco de dados, e ao desenvolvimento de aplicações Web, por exemplo);
	\item Facilidade de conectividade com outras linguagens de programação (\emph{bindings});
\end{itemize}

\subsection{Repositório de \emph{logs}}

Um ponto crucial para a realização de nossa trabalho são os \emph{logs} que iremos analisar e usar para desenvolver nossa solução. Para o melhor de nosso conhecimento, todos os outros trabalhos que focaram em técnicas de abstração de \emph{logs} o fizeram usando dados de ambientes de produção, e que não estão disponíveis publicamente.

Enquanto poderíamos usar um pequeno volume de dados de um computador local, ou gerar dados a partir de um ambiente simulados, acreditamos que essas soluções não apresentariam a complexidade existente em um ambiente de produção.

A disponibilização de \emph{logs} de forma pública não é uma prática comum, pois pode gerar vazamento de informações. A maioria dos registros que são disponibilizados publicamente são de ambientes simulados, o que pode não refletir o um ambiente de produção de uma empresa.

Para o nosso trabalho iremos utilizar o repositório de \emph{logs} \url{http://www.secrepo.com/}, que é mantido por membros da comunidade de segurança da informação. No decorrer de nosso trabalho iremos identificar quais \emph{logs} desse repositório melhor se adequarão ao nosso trabalho. Isso garante que tenhamos dados que refletem um ambiente existente na indústria, e também permite a reprodutibilidade de nosso trabalho.

\chapter{Utilização de processamento natural de linguagem para abstração de logs}\label{chap:proposta}

Nessa seção detalharemos como a solução que pretendemos produzir deve trabalhar. Mostrando a motivação para a solução, e também o detalhamento técnico da solução que imaginamos (passo a passo).

Nós imaginamos que nossa ferramenta seja inserida dentro do fluxo de do processamento de dados de uma IDS de host (responsável pela análise de \emph{logs}). Nesse cenário o caso mais comum para as fontes de dados são as entradas não estruturadas. Os arquivos de \emph{logs}, normalmente, tentam ser de mais fácil leitura para os humanos, em detrimento da facilidade de processamento, gerando problemas para serem analisados automaticamente por computadores. 

Uma abordagem que visa facilitar a análise dos dados por humanos é a de ``abstração de logs``, que visa abstrair eventos concretos, para seu conceito mais genérico. Por exemplo, veja as seguintes entradas de \emph{log}:

\begin{verbatim}
Invalid user developer from 116.255.160.35
Invalid user root from 116.255.160.32
Invalid user mancha from 116.255.170.55
\end{verbatim}
	
Todas essas entradas tem o mesmo ``formato``: \verb|Invalid user * from *|, onde os asteríscos (\emph{*}), se referem aos campos variáveis das entradas (ou seja, os que podem assumir valores diferentes), os outros campos (\emph{invalid}, \emph{user}, \emph{from}), são ditos, \emph{campos estáticos}. Ou seja, as trÊs entradas de \emph{log} acima podem ser \emph{abstraídas}, para um único \emph{tipo} de evento. 

De forma mais específica podemos dizer que as linhas acimas possuem um outro formato: \verb|Invalida user <user> from <ip>|, onde \verb|<user>| e \verb|<ip>| são \emph{placeholders} para o tipo de entidade a que o campo variável se refere. Ou seja, enquanto a abstração que vimos anteriormente permite identificarmos quais posições do \emph{log} são variáveis, a segunda abstração nos permite identificar a que essas posições se referem.

Essas abstrações são muito úteis na comunidade da segurança da informação. A primeira abordagem permite uma redução significativa no número de eventos tratados por um analista de segurança. No entanto, a segunda forma de abstração da uma capacidade de correlação aos eventos não disponível até então. Vamos tomar como exemplo as seguintes entradas:

{\small
\begin{verbatim}
lightdm: pam_unix(lightdm:session): session opened for user rogerio by (uid=0)
sudo:   rogerio : TTY=pts/3 ; PWD=/home/rogerio ; USER=root ; COMMAND=/bin/ls /root
sudo: pam_unix(sudo:session): session opened for user root by rogerio(uid=0)
sudo: pam_unix(sudo:session): session closed for user root
\end{verbatim}
}

Se realizarmos a abstração de \emph{log} nessas entradas, detectando as suas entidades, poderemos chegar aos seguintes eventos:

{\small
\begin{verbatim}
lightdm: pam_unix(lightdm:session): session opened for user <user> by (uid=<uid>)
sudo:   <user> : TTY=<tty> ; PWD=<pwd> ; USER=<user> ; COMMAND=<command>
sudo: pam_unix(sudo:session): session opened for user <user> by <user>(uid=<uid>)
sudo: pam_unix(sudo:session): session closed for user <user>
\end{verbatim}
}

Dessa forma um analista de segurança pode saber que um usuário chamado \emph{rogerio} fez login no sistema e logo em seguida esse mesmo usuário executou um comando usando o \emph{sudo}. Só podemos depreender isso dessas informações pois sabemos que os campos, em \emph{logs} de tipos diferentes (\emph{logs} heterogêneos) possuem uma entidade em comum (usuário).

Apesar das obvias vantagens da abstração de \emph{logs}, ela não é amplamente aplicada, pois necessita do esforço manual do analista de segurança para a geração de regras para a identificação do formato dos \emph{logs}, um trabalho que consome muito tempo, está sujeito a falhas, e pode ser comprometido pela mudança da estrutura dos \emph{logs} gerados pelos sistemas (fora do controle do analista).

A identificação de entidades também é importante para aplicação de outras técnicas de detecção de intrusão (onde imaginamos que nossa solução será inserida). A detecção de anomalias (uma técnica de detecção de intrusão), por exemplo, não apresenta desempenho satisfatório quando usamos somantes as informações textuais para procurar por ataques. O trabalho apresentado em \cite{li2013automatic} mostra isso.

Por outro lado, o trabalho apresentado em \cite{yen2013beehive} mostra bons resultados na detecção de intrusão através da análise de alguns tipos específicos de \emph{logs}, quando é feito um pré-processamento dos dados e deles são retirados um conjunto ``interessante'' de informações. Esse mesmo ganho é comprovado em \cite{xu2009detecting}, onde foi desenvolvido um método automático de retirada de informações semânticas dos \emph{logs}. No entanto, a técnica usada neste trabalho envolve a análise do código fonte da aplicação que gera os \emph{logs}. Em ambientes de grandes empresas nem sempre os softwares usados são de código aberto, o que torna essa técnica impossível de ser aplicada.

\section{Processamento natural de linguagem e extração de entidades}
Para superar essa barreira, são necessários mecanismos que permitam a abstração automática de eventos. No entanto, os trabalhos acadêmicos que encontramos se concentram em automatizar somente o primeiro caso de abstração que mostramos anteriormente \cite{vaarandi2003data, nagappan2010abstracting}, agrupando (com variável sucesso) tipos parecidos de \emph{logs}, mas sem identificar a quais entidades as partes variáveis se referem.

Nesse sentido o uso das técnicas de processamento de linguagem natural (PNL; NLP na sigla em inglês) pode ajudar a evoluir esse conceito. Podemos usar o PNL para encontrar o significado de uma frase (positivo ou negativo) e tentar encontrar as entidades referenciadas em uma dada linha de \emph{log} (usuário, IP de origem, sistema impactado, etc). Podemos ainda correlacionar automaticamente o mesmo tipo de entidade em diferentes \emph{logs} (mesmo entre aplicações diferentes).  Nesse sentido fomos inspirados pelos trabalhos apresentados em \cite{matos2010environment, duque2012processo}.

Além disso, acreditamos que as técnicas de PNL, podem nos ajudar a melhor classificar as entidades. Por exemplo, observe as entradas de log abaixo:

{\tiny
	\begin{verbatim}
	refused connect from 192.168.0.1:1231 to procedure ypproc_domain_nonack 
	connect to 192.168.0.1:25: Connection timed out
	\end{verbatim}
}

Enquanto a entidade \emph{192.168.0.1}, aparece nas duas entradas de logs (e nos dois casos ela é um IP), ela tem contextos diferentes. No primeiro caso a entidade é um IP de origem (isto é, está originando a ação), no segundo caso ela é o IP de destino (recebe uma ação). Esse tipo de diferença é importante durante o processo de análise de \emph{logs} e poder servir de insumo para tomada de decisões. Nesse caso, observe que o tipo da entidade, é indicada pelo contexto do \emph{log}, e as indicações do texto (a precedência das palavras \emph{from} e \emph{to}), indicam o tipo de cada uma das entidades.

Os avanços que esperamos alcançar aqui também podem gerar impactos no processo de consolidação de dados, um grande desafio existente hoje, não só nos IDSs como também para qualquer sistema de \emph{Big Data} \cite{zuech2015intrusion}. Em especial, se a classificação automática de entidades puder se feita de forma online (durante o  \emph{streaming} de dados), podemos começar a trabalhar de forma muito mais rápida, e com menor tempo de reação, para novos ataques, através da integração continua de dados.

\section{Proposta de Implementação}\label{sec:implementacao}

Dado o exposto anteriormente, o nosso objetivo com esse trabalho é um algoritmo, e implementar um solução de software, que permita a detecção de padrões em \emph{logs} de sistemas. A principal diferença de nossa abordagem para as que existem hoje em dia, é que não queremos somente agrupar \emph{logs} similares, como em \cite{vaarandi2003data}, mas também detectar ``entidades'' dentro dos \emph{logs}, através de técnicas de mineração de texto.

Nós visualizamos nossa solução sendo usada como a primeira etapa de processamento para o recebimento de \emph{logs}, de forma a sua saída (os \emph{logs}, agrupadas e com suas entidades categorizadas), possa ser armazenado para posterior consumo (por humanos ou por outras soluções de software).

Durante o desenvolvimento do nosso projeto, também será elaborada um métrica para avaliar o desempenho de nossa solução, quando comparada com as demais.


\chapter{Cronograma}\label{chap:cronograma}

O desenvolvimento deste trabalho se dará da seguinte forma:

\begin{enumerate}
	\item \label{rev-bibli} Revisão bibliográfica;
	\item \label{esc-base} Escolha de base de dados para análise;
	\item \label{imp-outras} Coleta/Implementação de outras soluções de abstração de \emph{logs};
	\item \label{def-pol} Definição de politica de análise de desempenho;
	\item \label{est-nltk} Estudo da biblioteca NLTK;
	\item \label{algo-abs} Definição de algorítimo para abstração de \emph{logs};
	\item \label{algo-clas} Definição de algorítimo para classificação de entidades;
	\item \label{imp-sol} Implementação da solução de software;
	\item \label{ava-des} Avaliação de desempenho da solução implementada;
	\item \label{esc-dis} Escrita da Dissertação;
	\item \label{pub-art} Publicação de artigos;	
\end{enumerate}

\begin{table}[!htbp]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		&\multicolumn{5}{c|}{2016}&\multicolumn{5}{c|}{2017}\\
		\hline
		&AGO&SET&OUT&NOV&DEZ&JAN&FEV&MAR&ABR&MAI\\
		\hline
		\ref{rev-bibli}& \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet & \textbullet \\
		\hline
		\ref{esc-base}& \textbullet & \textbullet &&&&&&&&\\
		\hline
		\ref{imp-outras}& \textbullet &\textbullet & \textbullet &&&&&&&\\
		\hline
		\ref{def-pol}& &&&\textbullet &\textbullet &&&&&\\
		\hline
		\ref{est-nltk}&&\textbullet &\textbullet &\textbullet &\textbullet &&&&&\\
		\hline
		\ref{algo-abs}& &&\textbullet&\textbullet&\textbullet&&&&&\\
		\hline
		\ref{algo-clas}& &&&\textbullet&\textbullet&\textbullet&\textbullet&&&\\
		\hline
		\ref{imp-sol}&&&&&&\textbullet&\textbullet&\textbullet&&\\
		\hline
		\ref{ava-des}&&&&&&&\textbullet&\textbullet&\textbullet&\textbullet\\
		\hline
		\ref{esc-dis}&&&&&&\textbullet&\textbullet&\textbullet&\textbullet&\textbullet\\
		\hline				
		\ref{pub-art}& & & & & \textbullet & & & & & \textbullet \\
		\hline					
	\end{tabular}
\end{table}

\chapter{Conclusão}\label{chap:conclusao}
Nessa proposta apresentamos a nossa ideia para implementação de uma solução de abstração de \emph{logs} com o uso de técnicas de processamento natural de linguagem.

Durante essa proposta apresentamos a lacuna existente hoje nas pesquisas de abstração de \emph{logs}, onde não identificamos nenhuma solução que possa realizar a extração de entidades dos \emph{logs} (que mostramos ser de grande importância, para o analista de segurança, e para a implementação de técnicas de detecção de intrusão). Também mostramos como acreditamos que as técnicas de processamento natural de linguagem pode ajudar na identificação de entidades (e de seus contextos).

Apresentamos também os dados e as tecnologias que pretendemos usar durante o desenvolvimento do nosso trabalho (lignuagem de programação Python, bibliotecas NLTK e scikit-learn, e o repositório de \emph{logs} \url{http://www.secrepo.com}{SecRepo}).

%Mostramos a necessidade da abstração de \emph{logs} (para facilitar o trabalho dos analistas de segurança e também de oferecer ao mesmo novos mecanismos de análise), e como a mesma ainda está sendo feita, em grande parte de forma manual.

% ---
% Finaliza a parte no bookmark do PDF
% para que se inicie o bookmark na raiz
% e adiciona espaço de parte no Sumário
% ---
\phantompart

% ---
% Conclusão
% ---
%\chapter*[Considerações finais]{Considerações finais}
%\addcontentsline{toc}{chapter}{Considerações finais}

% ----------------------------------------------------------
% - ELEMENTOS PÓS-TEXTUAIS
% ----------------------------------------------------------
\postextual

% ----------------------------------------------------------
% Referências bibliográficas
% ----------------------------------------------------------
\bibliography{bibliografia}

% ----------------------------------------------------------
% Glossário
% ----------------------------------------------------------
%
% Consulte o manual da classe abntex2 para orientações sobre o glossário.
%
%\glossar

% ----------------------------------------------------------
% Apêndices
% ----------------------------------------------------------

%---------------------------------------------------------------------
% -INDICE REMISSIVO
%---------------------------------------------------------------------

\phantompart

\printindex


\end{document}
